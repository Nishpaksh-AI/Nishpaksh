## Nishpaksh

**Nishpaksh** is an end-to-end framework for evaluating, comparing, and reporting the **fairness characteristics** of machine learning models. It computes fairness metrics across protected groups and generates structured, audit-ready summaries aligned with governance and compliance requirements.

The framework is compliant with the **TEC (Telecommunication Engineering Centre) Standard for Fairness Assessment and Rating of Artificial Intelligence Systems**, which presently covers **supervised learning models using tabular data**. It enables systematic documentation of model behavior, limitations, and fairness rationale, supporting transparent and accountable decision-making in regulated AI deployments.

ðŸ”— **TEC Standard (official document):**  
[Standard for Fairness Assessment and Rating of Artificial Intelligence Systems (TEC)](https://www.tec.gov.in/pdf/SDs/TEC%20Standard%20for%20fairness%20assessment%20and%20rating%20of%20AI%20systems%20Final%20v5%202023_07_04.pdf)

Subsequent versions of Nishpaksh aim to extend support to **bias mitigation guidance**, additional **data modalities**, and broader classes of machine learning models.

### Research Paper
The design and methodology of Nishpaksh are described in the following paper:

**Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models**  
Preprint available at: https://doi.org/10.48550/arXiv.2601.16926

### Authors
This tool was designed and built by:
- **Avinash Agarwal** (TEC/DoT, India)
- **Dr. Ranjitha Prasad** (IIIT Delhi, India)
- **Shashank Prakash** (IIIT Delhi, India)
